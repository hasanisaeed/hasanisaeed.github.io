---
title:  "Ù…ÙÙ‡ÙˆÙ… Ú¯Ø±Ø§Ø¯ÛŒØ§Ù† Ù†Ø²ÙˆÙ„ÛŒ ØªØµØ§Ø¯ÙÛŒ"
date: 2024-02-10T02:32:46+03:30
tags: ["Ú¯Ø±Ø§Ø¯ÛŒØ§Ù† Ù†Ø²ÙˆÙ„ÛŒ", "Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ", "ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø¹Ù…ÛŒÙ‚", "SGD", "Ù…ÙØ§Ù‡ÛŒÙ…"]
author: "Ø³Ø¹ÛŒØ¯ Ø­Ø³Ù†ÛŒ"
showToc: false
TocOpen: true
draft: false
hidemeta: false
comments: false
description: "Ú¯Ø±Ø§Ø¯ÛŒØ§Ù† Ù†Ø²ÙˆÙ„ÛŒ ØªØµØ§Ø¯ÙÛŒ"
hideSummary: false
ShowReadingTime: true
ShowBreadCrumbs: true
ShowPostNavLinks: true
ShowWordCount: false
ShowRssButtonInSectionTermList: true
UseHugoToc: true
cover:
    image: "https://raw.githubusercontent.com/hasanisaeed/hasanisaeed.github.io/main/content/posts/concept-of-SGD/images/sgd.webp"
    alt: "SGD"
    caption: "Ø§ÛŒÙ† Ø¹Ú©Ø³ Ø¨Ø§ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡ :)" 
    relative: true
    hidden: false
# editPost:
#     URL: "https://github.com/hasanisaeed/hasanisaeed.github.io/blob/main/content"
#     Text: "Ù…ØªÙ† Ø±Ùˆ ÙˆÛŒØ±Ø§ÛŒØ´ Ú©Ù† ğŸ¤—"
#     appendFilePath: true # to append file path to Edit link
---
![SGD](https://raw.githubusercontent.com/hasanisaeed/hasanisaeed.github.io/main/content/posts/concept-of-SGD/images/sgd.webp#center)

### Ù‚Ø³Ù…Øª Ø§ÙˆÙ„: Ø¯Ø±Ú© Ù…ÙØ§Ù‡ÛŒÙ… Ù¾Ø§ÛŒÙ‡
#### Ú¯Ø±Ø§Ø¯ÛŒØ§Ù† Ù†Ø²ÙˆÙ„ÛŒ Ú†ÛŒÙ‡ØŸ
ØªØµÙˆØ± Ú©Ù†ÛŒØ¯ Ú©Ù‡ Ø´Ù…Ø§ Ø¨Ø§Ù„Ø§ ÛŒÙ‡ Ú©ÙˆÙ‡ Ù‚Ø±Ø§Ø± Ú¯Ø±ÙØªÛŒÙ† Ùˆ Ù‡Ø¯Ù ØªÙˆÙ† Ø§ÛŒÙ† Ù‡Ø³Øª Ú©Ù‡ Ù…ÛŒØ®ÙˆØ§ÛŒÙ† Ø¨Ù‡ Ù¾Ø§ÛŒÛŒÙ† ØªØ±ÛŒÙ† Ù†Ù‚Ø·Ù‡ Ø¯Ø³Øª Ù¾ÛŒØ¯Ø§ Ú©Ù†ÛŒÙ†. Ø§ÛŒÙ†Ø¬Ø§Ø³Øª Ú©Ù‡:
> Ú¯Ø±Ø§Ø¯ÛŒØ§Ù† Ù†Ø²ÙˆÙ„ÛŒ Ú©Ù…Ú©ØªÙˆÙ† Ù…ÛŒÚ©Ù†Ù‡ ØªØ§ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø³ÛŒØ± Ø¨Ù‡ Ø³Ù…Øª Ù¾Ø§ÛŒÛŒÙ† Ø±Ùˆ Ù¾ÛŒØ¯Ø§ Ú©Ù†ÛŒÙ†.

Ø²ÛŒØ¨Ø§ÛŒÛŒ Ú¯Ø±Ø§Ø¯ÛŒØ§Ù† Ù†Ø²ÙˆÙ„ÛŒ Ø³Ø§Ø¯Ú¯ÛŒ Ùˆ Ø¸Ø±Ø§ÙØªØ´ Ù‡Ø³Øª. ØªÙˆÛŒ Ù…Ø«Ø§Ù„ Ú©ÙˆÙ‡ Ù…ÙˆÙ† Ù…ÙÙ‡ÙˆÙ…Ø§ÛŒÙ†Ù‡ Ú©Ù‡ Ø´Ù…Ø§ Ø¨Ø§ ÛŒÙ‡ Ù†Ù‚Ø·Ù‡ ØªØµØ§Ø¯ÙÛŒ Ø±ÙˆÛŒ Ú©ÙˆÙ‡ Ø³Ø¹ÛŒ Ù…ÛŒÚ©Ù†ÛŒÙ† Ú©Ù‡ Ø§Ø² Ú©ÙˆÙ‡ Ø¨ÛŒØ§Ù† Ù¾Ø§ÛŒÛŒÙ†. Ø¯Ø± Ù‡Ø± Ù…Ø±Ø­Ù„Ù‡ Ø´Ù…Ø§ Ø¨Ù‡ Ø§Ø·Ø±Ø§Ù Ù†Ú¯Ø§Ù‡ Ù…ÛŒÚ©Ù†ÛŒÙ† Ùˆ Ù‡Ù…Ø´ Ø³Ø¹ÛŒ Ù…ÛŒÚ©Ù†ÛŒÙ† Ú©Ù‡ ØªÙ†Ø¯ØªØ±ÛŒÙ† Ø´ÛŒØ¨ (Ú¯Ø±Ø§Ø¯ÛŒØ§Ù†) Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒÙ†. Ø§ÛŒÙ† Ú©Ø§Ø± Ø±Ùˆ Ø¨Ø§Ø±Ù‡Ø§ Ùˆ Ø¨Ø§Ø±Ù‡Ø§ ØªÚ©Ø±Ø§Ø± Ù…ÛŒÚ©Ù†ÛŒÙ†. Ø­Ø§Ù„Ø§ Ú†Ù‚Ø¯Ø±ØŸ Ø¨Ù‡Ø´ Ù…ÛŒØ±Ø³ÛŒÙ….

ØªÙˆÛŒ Ú¯Ø±Ø§Ø¯ÛŒØ§Ù† Ù†Ø²ÙˆÙ„ÛŒ Ù‡Ø± Ù‚Ø¯Ù… Ú©Ù‡ Ø¨Ù‡ Ù¾Ø§ÛŒÛŒÙ† Ø¨Ø±Ù…ÛŒØ¯Ø§Ø±ÛŒÙ†ØŒ Ø¨Ù‡ Ø§ÙˆÙ† Ù‚Ø¯Ù… ØªÙˆÙ† Ù…ÛŒÚ¯Ù† Ø§ØµÙ„Ø§Ø­Ø§ Ù†Ø±Ø® ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ ÛŒØ§ Ù‡Ù…ÙˆÙ† `learning rate`. 
> Ø§Ø­ØªÙ…Ø§Ù„Ø§ Ø¨Ø±Ø§Øª Ø³ÙˆØ§Ù„ Ù¾ÛŒØ´ Ø§ÙˆÙ…Ø¯Ù‡ Ú©Ù‡ Ù…Ù† Ù‚Ø¯Ù… Ø¨Ù„Ù†Ø¯ Ø¨Ø±Ø¯Ø§Ø±Ù… ÛŒØ§ Ù‚Ø¯Ù…Ù‡Ø§ÛŒ Ú©ÙˆÚ†ÛŒÚ©. Ú†ÛŒØ²Ø§ÛŒÛŒ Ú©Ù‡ Ø§Ù„Ø§Ù† Ø¨Ù‡ Ø°Ù‡Ù†Øª Ù…ÛŒØ§Ø¯ Ù…ÙÙ‡ÙˆÙ…Ø±ÛŒØ§Ø¶ÛŒ Ø¯Ø§Ø±Ù‡ Ú©Ù‡ Ø¹Ø¬Ù„Ù‡ Ù†Ú©Ù†ÛŒ Ùˆ Ø®Ø³ØªÙ‡ Ù†Ø´ÛŒ Ø¨Ø±Ø§Øª Ø¨ÛŒØ´ØªØ± Ø¨Ø§Ø² Ù…ÛŒÚ©Ù†Ù….

#### Ù…ÙÙ‡ÙˆÙ… 'ØªØµØ§Ø¯ÙÛŒ' Ø¯Ø± Ú¯Ø±Ø§Ø¯ÛŒØ§Ù† Ù†Ø²ÙˆÙ„ÛŒ ØªØµØ§Ø¯ÙÛŒ
ÙØ±Ø¶ Ú©Ù† Ø¨Ø§Ù„Ø§ Ú©ÙˆÙ‡ Ù…Ù‡ ØºÙ„ÛŒØ¸ Ú¯Ø±ÙØªÙ‡ Ùˆ ØªÙˆ Ù†Ù…ÛŒØªÙˆÙ†ÛŒ Ù‡Ù…Ù‡ Ø¬Ø§ Ø±Ùˆ Ø¨Ù‡ Ø®ÙˆØ¨ÛŒ Ø¨Ø¨ÛŒÙ†ÛŒ(Ù…Ø³ÛŒÙ„Ù‡ Ù‡Ø§Ù…ÙˆÙ† ØªÙˆÛŒ Ø¯Ù†ÛŒØ§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Ø§ÛŒÙ†Ø¬ÙˆØ±ÛŒ Ù‡Ø³ØªÙ†).Ø§Ø­ØªÙ…Ø§Ù„Ø§ Ù‚Ø¯Ù…Ù‡Ø§ÛŒ Ú©ÙˆÚ†ÛŒÚ© Ùˆ *ØªØµØ§Ø¯ÙÛŒ* Ø¨Ø±Ù…ÛŒØ¯Ø§Ø±ÛŒØŸ Ùˆ Ø³Ø¹ÛŒ Ù…ÛŒÚ©Ù†ÛŒ Ø¨Ø§Ø±Ù‡Ø§ Ùˆ Ø¨Ø§Ø±Ù‡Ø§ Ø§ÛŒÙ† Ú©Ø§Ø± Ø±Ùˆ ØªÚ©Ø±Ø§Ø± Ú©Ù†ÛŒ. ÙˆØ§Ø³Ù‡ Ù‡Ù…ÛŒÙ†Ù‡ Ú©Ù‡ ÛŒÙ‡ Ù…Ø³ÛŒØ± Ø²ÛŒÚ¯ Ø²Ø§Ú¯ Ù…Ø§Ù†Ù†Ø¯ Ø¯Ø§Ø±ÛŒ Ù‡Ù…Ø´ Ø·ÛŒ Ù…ÛŒÚ©Ù†ÛŒ!
> Ù¾Ø³ Ø§ÙˆÙ…Ø¯ÛŒÙ… *ØªØµØ§Ø¯ÙÛŒ* Ù‚Ø¯Ù… Ø¨Ø±Ø¯Ø§Ø´ØªÛŒÙ… Ùˆ Ù‡Ø± Ø¨Ø§Ø± Ø­ÙˆØ§Ø³ Ù…ÙˆÙ† Ù‡Ø³Øª Ú©Ù‡ Ù‚Ø¯Ù… Ø¨Ø¹Ø¯ÛŒ Ø±Ùˆ Ù…Ø­ØªØ§Ø· ØªØ± Ø¨Ø±Ø¯Ø§Ø±ÛŒÙ…. Ø§ÛŒÙ† Ù‡Ù…ÙˆÙ† Ù…ÙÙ‡ÙˆÙ… ØªØµØ§Ø¯ÙÛŒ Ø¨ÙˆØ¯Ù† Ù‡Ø³Øª.

### Ù‚Ø³Ù…Øª Ø¯ÙˆÙ…: Ø±ÛŒØ§Ø¶ÛŒØ§Øª Ù¾Ø´Øª Ù¾Ø±Ø¯Ù‡ SGD
#### Ú¯Ø§Ù…Ù‡Ø§ÛŒ Ú¯Ø±Ø§Ø¯ÛŒØ§Ù†
- Ù‚Ø¯Ù… Ø§ÙˆÙ„: Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡
Ø§Ø¨ØªØ¯Ø§ØŒ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ (ÙˆØ²Ù†â€ŒÙ‡Ø§) Ù…Ø¯Ù„ Ø®ÙˆØ¯ Ø±Ø§ Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…. Ø§ÛŒÙ† Ú©Ø§Ø± Ù…ÛŒâ€ŒØªÙˆÙ†Ù‡ Ø¨Ù‡ ØµÙˆØ±Øª ØªØµØ§Ø¯ÙÛŒ ÛŒØ§ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø±ÙˆØ´ Ø¯ÛŒÚ¯Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ø§Ù†Ø¬Ø§Ù… Ø¨Ø´Ù‡. Ù†Ù‚Ø·Ù‡ Ø´Ø±ÙˆØ¹ Ø¨Ø±Ø§ÛŒ SGD Ø­ÛŒØ§ØªÛŒ Ø§Ø³Øª Ø²ÛŒØ±Ø§ Ø¨Ø± Ù…Ø³ÛŒØ± Ø±Ø³ÛŒØ¯ Ø¨Ù‡ Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ù†Ù‚Ø·Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡ ØªØ§Ø«ÛŒØ± Ù…ÛŒØ°Ø§Ø±Ù‡. 
- Ù‚Ø¯Ù… Ø¯ÙˆÙ…: Ø§Ù†ØªØ®Ø§Ø¨ ØªØµØ§Ø¯ÙÛŒ
Ø¯Ø± Ù‡Ø± ØªÚ©Ø±Ø§Ø± Ø§Ø² ÙØ±Ø¢ÛŒÙ†Ø¯ Ø¢Ù…ÙˆØ²Ø´ØŒ SGD Ø¨Ù‡ ØµÙˆØ±Øª ØªØµØ§Ø¯ÙÛŒ ÛŒÚ© Ù†Ù‚Ø·Ù‡ Ø¯Ø§Ø¯Ù‡ (ÛŒØ§ ÛŒÚ© Ø¯Ø³ØªÙ‡ Ú©ÙˆÚ†Ú© Ø§Ø² Ù†Ù‚Ø§Ø· Ø¯Ø§Ø¯Ù‡) Ø±Ø§ Ø§Ø² Ú©Ù„ Ø¯ÛŒØªØ§Ø³Øª Ø§Ù†ØªØ®Ø§Ø¨ Ù…ÛŒâ€ŒÚ©Ù†Ù‡. Ø§ÛŒÙ†Ú©Ù‡ Ú©Ù‡ Ú¯ÙØªÛŒÙ… ØªØµØ§Ø¯ÙÛŒ ØªØµØ§Ø¯ÙÛŒØŒ Ø¨Ø®Ø§Ø·Ø± Ø§ÛŒÙ† Ù‚Ø³Ù…Øª Ø§Ø² Ø§Ù„Ú¯ÙˆØ±ØªÛŒÙ… Ø¨ÙˆØ¯! 
- Ù‚Ø¯Ù… Ø³ÙˆÙ…: Ù…Ø­Ø§Ø³Ø¨Ù‡ Ú¯Ø±Ø§Ø¯ÛŒØ§Ù† ÛŒØ§ Ù‡Ù…ÙˆÙ† Ø´ÛŒØ¨
Ú¯Ø±Ø§Ø¯ÛŒØ§Ù† ØªØ§Ø¨Ø¹ Ø²ÛŒØ§Ù† Ø±Ø§ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ú©Ù†ÛŒÙ†ØŒ Ø§Ù…Ø§ ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ù†Ù‚Ø§Ø· Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ú©Ù‡ Ø¨Ù‡ ØµÙˆØ±Øª ØªØµØ§Ø¯ÙÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯. Ú¯Ø±Ø§Ø¯ÛŒØ§Ù† ÛŒÚ© Ø¨Ø±Ø¯Ø§Ø± Ø§Ø³Øª Ú©Ù‡ Ø¯Ø± Ø¬Ù‡Øª Ø§ÙØ²Ø§ÛŒØ´ ØªÙ†Ø¯ØªØ±ÛŒÙ† ØªØ§Ø¨Ø¹ Ø²ÛŒØ§Ù† Ø§Ø´Ø§Ø±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Ø¯Ø± Ù…ÙÙ‡ÙˆÙ… SGDØŒ ÛŒØ¹Ù†ÛŒ Ú†Ú¯ÙˆÙ†Ù‡ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ Ø±Ùˆ Ø¨Ø±Ø§ÛŒ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ± Ú©Ø±Ø¯Ù† Ù…Ø¯Ù„ Ø¨Ø±Ø§ÛŒ Ø¢Ù† Ù†Ù‚Ø·Ù‡ Ø¯Ø§Ø¯Ù‡ Ø®Ø§Øµ ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒÙ…. 

$$g_t = \nabla_\theta f_t(\theta_{t-1})$$

- Ù‚Ø¯Ù… Ú†Ù‡Ø§Ø±Ù…: Ø¢Ù¾Ø¯ÛŒØª Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§
#### Ø¯Ø±Ú© Ù…ÙÙ‡ÙˆÙ… Ù†Ø±Ø® ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ
ÙÙ‡Ù…ÛŒØ¯Ù† Ùˆ Ø§Ù†ØªØ®Ø§Ø¨ Ø¯Ø±Ø³Øª Ù¾Ø§Ø±Ø§Ù…ØªØ± Ù†Ø±Ø® ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒØŒ Ù†Ù‚Ø´ Ø²ÛŒØ§Ø¯ÛŒ Ø¯Ø±  Ú©Ø§Ø±Ø§Ù…Ø¯ÛŒ Ù…Ø¯Ù„ SGD Ø¯Ø§Ø±Ù‡.

**Ø§Ú¯Ø± Ù†Ø±Ø® ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø¨Ø²Ø±Ú¯ Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ø´Ù‡ Ú†Ù‡ Ø§ØªÙØ§Ù‚ÛŒ  Ù…ÛŒÙØªÙ‡ØŸ** ÙØ±Ø¶ Ú©Ù† Ø¨Ø§ Ú¯Ø§Ù…Ù‡Ø§ÛŒ Ø¨Ù„Ù†Ø¯ Ø¨Ø®ÙˆØ§ÛŒÙ… Ø¨Ù‡ Ø¬Ù„Ùˆ Ø­Ø±Ú©Øª Ú©Ù†ÛŒÙ… Ùˆ Ø§ÙˆÙ† Ù†Ù‚Ø·Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡ Ø±Ùˆ Ù¾ÛŒØ¯Ø§ Ú©Ù†ÛŒÙ…. Ù…Ù…Ú©Ù†Ù‡ ÙÚ© Ú©Ù†ÛŒÙ† Ú©Ù‡ Ø®Ø¨ Ø³Ø±ÛŒØ¹ØªØ± Ø¨Ù‡ Ù¾Ø§ÛŒÛŒÙ† ØªØ±ÛŒÙ† Ù†Ù‚Ø·Ù‡ Ù…ÛŒØ±Ø³Ù… Ø§Ù…Ø§Ø§ÛŒÙ† Ú©Ø§Ø± Ø¨Ø§Ø¹Ø« Ù…ÛŒØ´Ù‡ Ù…Ø«Ù„Ø§ ÛŒÙ‡ Ú¯Ø§Ù… Ø¬Ù„ÙˆØªØ± Ø´Ù…Ø§ Ù†Ù‚Ø·Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡ (Ù¾Ø§ÛŒÛŒÙ† ØªØ±ÛŒÙ† Ù†Ù‚Ø·Ù‡) Ø¨Ø§Ø´Ù‡ Ùˆ Ø´Ù…Ø§ Ø§Ø² Ø±ÙˆØ´ Ø¨Ù¾Ø±ÛŒ Ùˆ Ù…Ù…Ú©Ù†Ù‡ Ù†Ù‚Ø·Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡ Ø²ÛŒØ± Ù¾Ø§ØªØŒ ÛŒÙ‡ Ú©Ù… Ø¬Ù„ÙˆØªØ± Ø¨Ø§Ø´Ù‡ Ùˆ ØªÙˆÛŒ Ù‡ÛŒ Ø¹Ù‚Ø¨ Ùˆ Ø¬Ù„Ùˆ Ø¨Ù¾Ø±ÛŒ.

**Ø­Ø§Ù„Ø§ Ø§Ú¯Ù‡ Ù†Ø±Ø® ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø±Ùˆ Ú©Ù… Ø¨Ú¯ÛŒØ±ÛŒ Ú†Ù‡ Ø§ØªÙØ§Ù‚ÛŒ Ù…ÛŒÙØªÙ‡ØŸ** ÙÚ© Ú©Ù†Ù… ÙˆØ§Ø¶Ø­ Ø¨Ø§Ø´Ù‡ØŸ Ù†Ù‡ØŸ ÙØ±Ø¶ Ú©Ù† Ø§ÙØªØ§Ø¯ÛŒ ØªÙˆÛŒ ÛŒÙ‡ Ú¯ÙˆØ¯ÛŒ Ùˆ  Ù‚Ø¯Ù…Ù‡Ø§Øª Ø®ÛŒÙ„ÛŒ Ú©ÙˆÚ†ÛŒÚ© Ù‡Ø³Øª. Ø­Ø§Ù„Ø§ Ù‡Ø±Ú†Ù‚Ø¯Ø± Ø¨Ù‡ Ú†Ù¾ Ùˆ Ø±Ø§Ø³Øª Ù…ÛŒØ±ÛŒ Ø¨Ø§Ø²Ù… ØªÙˆÛŒ Ú¯ÙˆØ¯ÛŒ Ù‡Ø³ØªÛŒ! Ùˆ Ù…Ø´Ú©Ù„ Ø¨Ø¹Ø¯ÛŒ Ù‡Ù… Ø§ÛŒÙ† Ù‡Ø³Øª Ú©Ù‡ Ø®ÛŒÙ„ÛŒ Ú©Ù†Ø¯ Ø¯Ø§Ø±ÛŒ Ø¨Ù‡ Ø³Ù…Øª Ù‡Ø¯ÙØª Ú©Ù‡ Ù‡Ù…ÙˆÙ† Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ù¾Ø§ÛŒÛŒÙ† Ù†Ù‚Ø·Ù‡ Ù‡Ø³Øª Ù…ÛŒØ±Ø³ÛŒ.

**Ø®Ø¨ Ù¾Ø³ Ú†Ø¬ÙˆØ±ÛŒ Ù‚Ø¯Ù…Ù‡Ø§ Ø±Ùˆ Ø¨Ø±Ø¯Ø§Ø±Ù…ØŸ**
ÙˆØ§Ø³Ù‡ Ø§ÛŒÙ† Ú©Ø§Ø± ØªÙˆØµÛŒÙ‡ Ø´Ø¯Ù‡ Ú©Ù‡ Ù†Ù‡ Ù‚Ø¯Ù…Ù‡Ø§ÛŒ Ø¨Ù„Ù†Ø¯ Ø¨Ø±Ø¯Ø§Ø±ÛŒÙ† Ùˆ Ù†Ù‡ Ù‚Ø¯Ù…ÛŒ Ø®ÛŒÙ„ÛŒ Ú©ÙˆÚ†ÛŒÚ©. Ù†Ø±Ø® ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø±Ùˆ Ø§Ø² Ø·Ø±ÛŒÙ‚ Ø³Ø¹ÛŒ Ùˆ Ø®Ø·Ø§ Ø¨Ø¯Ø³Øª Ù…ÛŒØ§Ø±Ù† Ùˆ Ù…ÛŒØ§Ù† Ø¯Ø± Ø·ÙˆÙ„ Ø²Ù…Ø§Ù† Ù…Ù‚Ø¯Ø§Ø±Ø´ Ø±Ùˆ Ú©Ù… Ù…ÛŒÚ©Ù†Ù†.

> ÛŒÙ‡ Ø³Ø±ÛŒ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ù‡Ø§ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ú©Ø§Ø± Ù…Ø·Ø±Ø­ Ø´Ø¯Ù‡ Ú©Ù‡ Ø³Ø±Ú† Ú©Ù†ÛŒÙ† Ø¯Ø³Øª ØªÙˆÙ† Ù…ÛŒØ§Ø¯. Ù…Ø«Ù„Ø§ Ø¨ÛŒØ§ÛŒÙ… Ø¨Ù‡ ØµÙˆØ±Øª Ù†Ù…Ø§ÛŒÛŒ Ù†Ø±Ø® Ø±Ùˆ Ú©Ù… Ú©Ù†ÛŒÙ… ÛŒØ§ Ø¨ÛŒØ§Ù† Ø§Ø² ÛŒÙ‡ Ø³Ø±ÛŒ Ù…ØªØ¯Ù‡Ø§ Ú©Ù‡ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…Ù‡Ø§ÛŒÛŒ Ù…Ø«Ù„Ø§ `Adam` Ø§Ø²Ø´ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒÚ©Ù†Ù†ØŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒÙ… Ùˆ ...

### Ù‚Ø³Ù…Øª Ø³ÙˆÙ…: Ø¨Ø±ÛŒÙ… Ø³Ù…Øª Ú©Ø¯Ù†ÙˆÛŒØ³ÛŒ SGD
Ø®Ø¨ Ø§ÙˆÙ„ Ù…ÛŒØ§Ù… Ú©Ø¯ Ù¾Ø§ÛŒØªÙˆÙ† Ø±Ùˆ Ø¨Ù‡ Ø·ÙˆÙ„ Ú©Ø§Ù…Ù„ Ø§ÛŒÙ†Ø¬Ø§ Ù…ÛŒØ°Ø§Ø±Ù…:

<details>
<summary> Ú©Ø¯ Ù¾ÛŒØ§Ø¯Ù‡ Ø³Ø§Ø²ÛŒ Ø´Ø¯Ù‡ Ø¨Ø§ Ù¾Ø§ÛŒØªÙˆÙ† </summary>

```python
class SGDRegressor:
    def __init__(self, learning_rate=0.01, epochs=100, batch_size=1, reg=None, reg_param=0.0):
        """
        Constructor for the SGDRegressor.

        Parameters:
        learning_rate (float): The step size used in each update.
        epochs (int): Number of passes over the training dataset.
        batch_size (int): Number of samples to be used in each batch.
        reg (str): Type of regularization ('l1' or 'l2'); None if no regularization.
        reg_param (float): Regularization parameter.

        The weights and bias are initialized as None and will be set during the fit method.
        """
        self.learning_rate = learning_rate
        self.epochs = epochs
        self.batch_size = batch_size
        self.reg = reg
        self.reg_param = reg_param
        self.weights = None
        self.bias = None

    def fit(self, X, y):
        """
        Fits the SGDRegressor to the training data.

        Parameters:
        X (numpy.ndarray): Training data, shape (m_samples, n_features).
        y (numpy.ndarray): Target values, shape (m_samples,).

        This method initializes the weights and bias, and then updates them over a number of epochs.
        """
        m, n = X.shape  # m is number of samples, n is number of features
        self.weights = np.zeros(n)
        self.bias = 0

        for _ in range(self.epochs):
            indices = np.random.permutation(m)
            X_shuffled = X[indices]
            y_shuffled = y[indices]

            for i in range(0, m, self.batch_size):
                X_batch = X_shuffled[i:i+self.batch_size]
                y_batch = y_shuffled[i:i+self.batch_size]

                gradient_w = -2 * np.dot(X_batch.T, (y_batch - np.dot(X_batch, self.weights) - self.bias)) / self.batch_size
                gradient_b = -2 * np.sum(y_batch - np.dot(X_batch, self.weights) - self.bias) / self.batch_size

                if self.reg == 'l1':
                    gradient_w += self.reg_param * np.sign(self.weights)
                elif self.reg == 'l2':
                    gradient_w += self.reg_param * self.weights

                self.weights -= self.learning_rate * gradient_w
                self.bias -= self.learning_rate * gradient_b

    def predict(self, X):
        """
        Predicts the target values using the linear model.

        Parameters:
        X (numpy.ndarray): Data for which to predict target values.

        Returns:
        numpy.ndarray: Predicted target values.
        """
        return np.dot(X, self.weights) + self.bias

    def compute_loss(self, X, y):
        """
        Computes the loss of the model.

        Parameters:
        X (numpy.ndarray): The input data.
        y (numpy.ndarray): The true target values.

        Returns:
        float: The computed loss value.
        """
        return (np.mean((y - self.predict(X)) ** 2) + self._get_regularization_loss()) ** 0.5

    def _get_regularization_loss(self):
        """
        Computes the regularization loss based on the regularization type.

        Returns:
        float: The regularization loss.
        """
        if self.reg == 'l1':
            return self.reg_param * np.sum(np.abs(self.weights))
        elif self.reg == 'l2':
            return self.reg_param * np.sum(self.weights ** 2)
        else:
            return 0

    def get_weights(self):
        """
        Returns the weights of the model.

        Returns:
        numpy.ndarray: The weights of the linear model.
        """
        return self.weights
```

<details>
</details>

<summary> Ú©Ø¯ Ù¾ÛŒØ§Ø¯Ù‡ Ø³Ø§Ø²ÛŒ Ø´Ø¯Ù‡ Ø¨Ø§ C </summary>
</details>

#### Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ SGD Ø¯Ø± Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ†
#### Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ SGD Ø¯Ø± Sci-kit Learn Ùˆ Tensorflow

### Ù‚Ø³Ù…Øª Ú†Ù‡Ø§Ø±Ù…: Ù…Ø²Ø§ÛŒØ§ Ùˆ Ú†Ø§Ù„Ø´Ù‡Ø§ÛŒ SGD
#### Ú†Ø±Ø§ SGD Ø±Ùˆ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒÙ…ØŸ
#### ØºÙ„Ø¨Ù‡ Ø¨Ø± Ú†Ø§Ù„Ø´â€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø· Ø¨Ø§ SGD

###  Ù‚Ø³Ù…Øª Ù¾Ù†Ø¬Ù…: ÛŒÙ‡ Ú©Ù… ÙØ±Ø§ØªØ± Ø§Ø² Ù…ÙØ§Ù‡ÛŒÙ… Ø¨Ø±ÛŒÙ…

#### Ø§Ù†ÙˆØ§Ø¹ Ù…Ø®ØªÙ„Ù SGD
#### Ø¢ÛŒÙ†Ø¯Ù‡â€ŒÛŒ SGD

### Ù†ØªÛŒØ¬Ù‡ Ú¯ÛŒØ±ÛŒ
