---
title:  "مفهوم گرادیان نزولی تصادفی"
date: 2024-02-10T02:32:46+03:30
tags: ["گرادیان نزولی", "هوش مصنوعی", "یادگیری عمیق", "SGD", "مفاهیم"]
author: "سعید حسنی"
showToc: false
TocOpen: true
draft: false
hidemeta: false
comments: false
description: "گرادیان نزولی تصادفی"
hideSummary: false
ShowReadingTime: true
ShowBreadCrumbs: true
ShowPostNavLinks: true
ShowWordCount: false
ShowRssButtonInSectionTermList: true
UseHugoToc: true
cover:
    image: "https://raw.githubusercontent.com/hasanisaeed/hasanisaeed.github.io/main/content/posts/concept-of-SGD/images/sgd.webp"
    alt: "SGD"
    caption: "این عکس با هوش مصنوعی تولید شده :)" 
    relative: true
    hidden: false
# editPost:
#     URL: "https://github.com/hasanisaeed/hasanisaeed.github.io/blob/main/content"
#     Text: "متن رو ویرایش کن 🤗"
#     appendFilePath: true # to append file path to Edit link
---
![SGD](https://raw.githubusercontent.com/hasanisaeed/hasanisaeed.github.io/main/content/posts/concept-of-SGD/images/sgd.webp#center)

### قسمت اول: درک مفاهیم پایه
#### گرادیان نزولی چیه؟
تصور کنید که شما بالا یه کوه قرار گرفتین و هدف تون این هست که میخواین به پایین ترین نقطه دست پیدا کنین. اینجاست که:
> گرادیان نزولی کمکتون میکنه تا بهترین مسیر به سمت پایین رو پیدا کنین.

زیبایی گرادیان نزولی سادگی و ظرافتش هست. توی مثال کوه مون مفهوماینه که شما با یه نقطه تصادفی روی کوه سعی میکنین که از کوه بیان پایین. در هر مرحله شما به اطراف نگاه میکنین و همش سعی میکنین که تندترین شیب (گرادیان) انتخاب کنین. این کار رو بارها و بارها تکرار میکنین. حالا چقدر؟ بهش میرسیم.

توی گرادیان نزولی هر قدم که به پایین برمیدارین، به اون قدم تون میگن اصلاحا نرخ یادگیری یا همون `learning rate`. 
> احتمالا برات سوال پیش اومده که من قدم بلند بردارم یا قدمهای کوچیک. چیزایی که الان به ذهنت میاد مفهومریاضی داره که عجله نکنی و خسته نشی برات بیشتر باز میکنم.

#### مفهوم 'تصادفی' در گرادیان نزولی تصادفی
فرض کن بالا کوه مه غلیظ گرفته و تو نمیتونی همه جا رو به خوبی ببینی(مسیله هامون توی دنیای واقعی اینجوری هستن).احتمالا قدمهای کوچیک و *تصادفی* برمیداری؟ و سعی میکنی بارها و بارها این کار رو تکرار کنی. واسه همینه که یه مسیر زیگ زاگ مانند داری همش طی میکنی!
> پس اومدیم *تصادفی* قدم برداشتیم و هر بار حواس مون هست که قدم بعدی رو محتاط تر برداریم. این همون مفهوم تصادفی بودن هست.

### قسمت دوم: ریاضیات پشت پرده SGD
#### گامهای گرادیان
- قدم اول: مقداردهی اولیه
- قدم دوم: انتخاب تصادفی
- قدم سوم: محاسبه گرادیان یا همون شیب
  
$$g_t = \nabla_\theta f_t(\theta_{t-1})$$

$$C_p[\ce{H2O(l)}] = \pu{75.3 J // mol K}$$


- قدم چهارم: آپدیت پارامترها
#### درک مفهوم نرخ یادگیری

### قسمت سوم: بریم سمت کدنویسی SGD
#### پیاده‌سازی SGD در مدل‌های یادگیری ماشین
#### پیاده‌سازی SGD در Sci-kit Learn و Tensorflow

### قسمت چهارم: مزایا و چالشهای SGD
#### چرا SGD رو انتخاب کنیم؟
#### غلبه بر چالش‌های مرتبط با SGD

###  قسمت پنجم: یه کم فراتر از مفاهیم بریم

#### انواع مختلف SGD
#### آینده‌ی SGD

### نتیجه گیری
